{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b830d-2ead-40ff-8d12-c43f3d0e2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install llmcompressor Tool\n",
    "!pip install llmcompressor==0.5.2 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd550fee-758b-4281-a628-5cb60378bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate LLM Compressor is installed\n",
    "!pip list | grep llmcompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b0d19-51b3-4960-ad89-e353e35b3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Python script to quantise the model\n",
    "\n",
    "from quantiser import quantise_model\n",
    "\n",
    "# You can view this code by opening the Python file from the File Explorer. \n",
    "quantise_model(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", scheme=\"W4A16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4fdcd-d832-4bd3-9f16-3a14fe254ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review contents of the file \n",
    "!ls -lsah TinyLlama/TinyLlama-1.1B-Chat-v1.0-W4A16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55cc6f-41ac-4353-b71e-3d5e15d3efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy of the model. We will be using lm-eval script in vLLM.\n",
    "!pip install vllm==0.9.1 lm-eval==0.4.7 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee7517-c4ce-4cf4-a558-a5b599dbdfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate unquantized model\n",
    "# !lm-eval --model vllm --model_args pretrained=TinyLlama/TinyLlama-1.1B-Chat-v1.0,tensor_parallel_size=1 \\\n",
    "# --limit 250 --tasks hellaswag --num_fewshot 5 --batch_size 5\n",
    "\n",
    "import os \n",
    "os.environ[\"HF_TOKEN\"] = \"token\"\n",
    "\n",
    "!time lm-eval \\\n",
    "  --model vllm \\\n",
    "  --model_args pretrained=TinyLlama/TinyLlama-1.1B-Chat-v1.0,tensor_parallel_size=1,gpu_memory_utilization=0.8 \\\n",
    "  --limit 250 \\\n",
    "  --tasks hellaswag \\\n",
    "  --num_fewshot 5 \\\n",
    "  --batch_size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea2199-a2b2-42bd-9e2c-961ce238e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we run the same command against the post-quantized model.\n",
    "# Note: You will need specify the Tokenizer explicitly.\n",
    "\n",
    "!time lm-eval \\\n",
    "  --model vllm \\\n",
    "  --model_args pretrained=TinyLlama/TinyLlama-1.1B-Chat-v1.0-W4A16,tokenizer=TinyLlama/TinyLlama-1.1B-Chat-v1.0,tensor_parallel_size=1,gpu_memory_utilization=0.8 \\\n",
    "  --limit 250 \\\n",
    "  --tasks hellaswag \\\n",
    "  --num_fewshot 5 \\\n",
    "  --batch_size 5\n",
    "\n",
    "# !time lm-eval --model vllm --model_args pretrained=TinyLlama/TinyLlama-1.1B-Chat-v1.0-W4A16,tokenizer=TinyLlama/TinyLlama-1.1B-Chat-v1.0,tensor_parallel_size=1 \\\n",
    "# --limit 250 --tasks hellaswag --num_fewshot 5 --batch_size 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e9b3c-8a85-41c1-91f3-592eb78248f0",
   "metadata": {},
   "source": [
    "By comparsing the pre-quantized-eval and post-quantized-eval,\n",
    "\n",
    "The value reduces from 0.572 to 0.564\n",
    "\n",
    "Accuracy Recovery = Post-quantized-accuracy / Pre-quantized-accuracy.\n",
    "\n",
    "So, the recovery here is 0.564 / 0.572 * 100% = 98.6%\n",
    "\n",
    "Acutally, you have to run more than 500,000 evaluations on quantized models, which retains about 99% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
